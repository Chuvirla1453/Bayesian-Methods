{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eB7G5AcVG_yq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "lr = 1e-3\n",
        "mc_samples = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, dropout_p=0.3, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def penultimate_acts(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "MQRJtUktbkpx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_mnist = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.expand(3, -1, -1))\n",
        "])\n",
        "\n",
        "train_id = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n",
        "test_id = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n",
        "test_ood = datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\n",
        "\n",
        "train_id_loader = DataLoader(train_id, batch_size=batch_size, shuffle=True)\n",
        "test_id_loader = DataLoader(test_id, batch_size=batch_size, shuffle=False)\n",
        "test_ood_loader = DataLoader(test_ood, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "PA1C8Cn5e-9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c84bc9-0ee8-46e7-b1f0-5f4f10943aaa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:19<00:00, 8.55MB/s]\n",
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.84MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.20MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.53MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, epochs, lr):\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        correct_samples = 0\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits = model(x)\n",
        "            loss = loss_function(logits, y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = logits.argmax(dim=1)\n",
        "\n",
        "            correct_samples += (preds == y).sum().item()\n",
        "\n",
        "        print(f'Epoch {epoch}; Train loss {total_loss / len(train_loader)}; Accuracy {correct_samples / len(train_loader.dataset) * 100}')"
      ],
      "metadata": {
        "id": "Eo39obOXgBEF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ood_metrics(id_scores, ood_scores):\n",
        "    y_true = np.concatenate([\n",
        "        np.zeros_like(id_scores),\n",
        "        np.ones_like(ood_scores)\n",
        "    ])\n",
        "    scores = np.concatenate([id_scores, ood_scores])\n",
        "\n",
        "    auroc = roc_auc_score(y_true, scores)\n",
        "    aupr = average_precision_score(y_true, scores)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
        "    target_tpr = 0.95\n",
        "    idxs = np.where(tpr >= target_tpr)[0]\n",
        "    if len(idxs) > 0:\n",
        "        fpr95 = fpr[idxs[0]]\n",
        "    else:\n",
        "        fpr95 = 1.0\n",
        "\n",
        "    print(f'AUROC {auroc}')\n",
        "    print(f'AUPR {aupr}')\n",
        "    print(f'FPR@95%TPR {fpr95}')\n",
        "\n",
        "    return auroc, aupr, fpr95"
      ],
      "metadata": {
        "id": "0JQs1hPzhLke"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_softmax_ood_scores(model, id_loader, ood_loader):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    id_scores = []\n",
        "    ood_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, _ in id_loader:\n",
        "            x = x.to(device)\n",
        "            logits = model(x)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            max_probs, _ = probs.max(dim=1)\n",
        "            scores = 1.0 - max_probs\n",
        "\n",
        "            id_scores.append(scores.cpu().numpy())\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, _ in ood_loader:\n",
        "            x = x.to(device)\n",
        "            logits = model(x)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            max_probs, _ = probs.max(dim=1)\n",
        "            scores = 1.0 - max_probs\n",
        "\n",
        "            ood_scores.append(scores.cpu().numpy())\n",
        "\n",
        "    id_scores = np.concatenate(id_scores)\n",
        "    ood_scores = np.concatenate(ood_scores)\n",
        "\n",
        "    return id_scores, ood_scores\n",
        "\n",
        "\n",
        "def get_mcd_ood_entropy(model, x, T=20):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        probs_T = []\n",
        "        for _ in range(T):\n",
        "            logits = model(x)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "\n",
        "            probs_T.append(probs.unsqueeze(0))\n",
        "\n",
        "        probs_T = torch.cat(probs_T, dim=0)\n",
        "\n",
        "    p_mean = probs_T.mean(dim=0)\n",
        "\n",
        "    eps = 1e-8\n",
        "    entropy = -torch.sum(p_mean * torch.log(p_mean + eps), dim=1)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "\n",
        "def get_mcd_ood_scores(model, id_loader, ood_loader, T=20):\n",
        "    model.to(device)\n",
        "\n",
        "    id_scores = []\n",
        "    ood_scores = []\n",
        "\n",
        "    for x, _ in id_loader:\n",
        "        x = x.to(device)\n",
        "        entropy = get_mcd_ood_entropy(model, x, T=T)\n",
        "\n",
        "        id_scores.append(entropy.cpu().numpy())\n",
        "\n",
        "    for x, _ in ood_loader:\n",
        "        x = x.to(device)\n",
        "        entropy = get_mcd_ood_entropy(model, x, T=T)\n",
        "\n",
        "        ood_scores.append(entropy.cpu().numpy())\n",
        "\n",
        "    id_scores = np.concatenate(id_scores)\n",
        "    ood_scores = np.concatenate(ood_scores)\n",
        "\n",
        "    return id_scores, ood_scores"
      ],
      "metadata": {
        "id": "nJFjjalbiq3N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(dropout_p=0.3, num_classes=10)\n",
        "train(model, train_id_loader, epochs=epochs, lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UMXfem4lQo2",
        "outputId": "40fe8f61-b395-4f11-92dd-6f2044f8ceeb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1; Train loss 1.7195650561691245; Accuracy 37.062\n",
            "Epoch 2; Train loss 1.3484908942981144; Accuracy 51.25999999999999\n",
            "Epoch 3; Train loss 1.2170067173440744; Accuracy 56.535999999999994\n",
            "Epoch 4; Train loss 1.1177400934421802; Accuracy 60.474000000000004\n",
            "Epoch 5; Train loss 1.0409339074893376; Accuracy 62.93\n",
            "Epoch 6; Train loss 0.9829035279391062; Accuracy 65.12\n",
            "Epoch 7; Train loss 0.9399666982843443; Accuracy 66.536\n",
            "Epoch 8; Train loss 0.9062132138730316; Accuracy 68.10199999999999\n",
            "Epoch 9; Train loss 0.8622144721353145; Accuracy 69.674\n",
            "Epoch 10; Train loss 0.8313267046533277; Accuracy 70.574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_id_scores, softmax_ood_scores = get_softmax_ood_scores(model, test_id_loader, test_ood_loader)\n"
      ],
      "metadata": {
        "id": "oTXN2uEnlbjD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auroc, aupr, fpr95 = compute_ood_metrics(softmax_id_scores, softmax_ood_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M20ULiJBl7US",
        "outputId": "a454f5c0-4c08-41cf-f399-aa5c4a6722e9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC 0.60268526\n",
            "AUPR 0.5507565766851117\n",
            "FPR@95%TPR 0.7775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcd_id_scores, mcd_ood_scores = get_mcd_ood_scores(model, test_id_loader, test_ood_loader)"
      ],
      "metadata": {
        "id": "fmkJm3jpl9-l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcd_auroc, mcd_aupr, mcd_fpr95 = compute_ood_metrics(mcd_id_scores, mcd_ood_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcFrCBvxmhI3",
        "outputId": "5756950b-cb61-4c53-b8c9-1c771f03d087"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC 0.704343935\n",
            "AUPR 0.6273927905553729\n",
            "FPR@95%TPR 0.6566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_react_ood_scores(model, id_loader, ood_loader, percentile=90):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    id_penultimate_activations_list = []\n",
        "    with torch.no_grad():\n",
        "        for x, _ in id_loader:\n",
        "            x = x.to(device)\n",
        "            penultimate_acts = model.penultimate_acts(x)\n",
        "            id_penultimate_activations_list.append(penultimate_acts.cpu().numpy())\n",
        "\n",
        "    all_id_penultimate_activations = np.concatenate(id_penultimate_activations_list)\n",
        "\n",
        "    c = np.percentile(all_id_penultimate_activations, percentile)\n",
        "    c_tensor = torch.tensor(c, device=device)\n",
        "\n",
        "    id_scores = []\n",
        "    ood_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, _ in id_loader:\n",
        "            x = x.to(device)\n",
        "            penultimate_acts = model.penultimate_acts(x)\n",
        "\n",
        "            h_react = torch.min(penultimate_acts, c_tensor)\n",
        "\n",
        "            x = F.relu(h_react)\n",
        "            x = model.dropout(x)\n",
        "            react_logits = model.fc2(x)\n",
        "\n",
        "            energy_score = -torch.logsumexp(react_logits, dim=1)\n",
        "            id_scores.append(energy_score.cpu().numpy())\n",
        "\n",
        "        for x, _ in ood_loader:\n",
        "            x = x.to(device)\n",
        "            penultimate_acts = model.penultimate_acts(x)\n",
        "\n",
        "            h_react = torch.min(penultimate_acts, c_tensor)\n",
        "\n",
        "            x = F.relu(h_react)\n",
        "            x = model.dropout(x)\n",
        "            react_logits = model.fc2(x)\n",
        "\n",
        "            energy_score = -torch.logsumexp(react_logits, dim=1)\n",
        "            ood_scores.append(energy_score.cpu().numpy())\n",
        "\n",
        "    id_scores = np.concatenate(id_scores)\n",
        "    ood_scores = np.concatenate(ood_scores)\n",
        "\n",
        "    return id_scores, ood_scores"
      ],
      "metadata": {
        "id": "vJlnRGiImmA9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "react_id_scores, react_ood_scores = get_react_ood_scores(model, test_id_loader, test_ood_loader)"
      ],
      "metadata": {
        "id": "v-htlUvQdOvu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "react_auroc, react_aupr, react_fpr95 = compute_ood_metrics(react_id_scores, react_ood_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nohlgfF-dENf",
        "outputId": "059899ab-17c5-4278-8e4f-cbb96c1130d0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC 0.9180067650000001\n",
            "AUPR 0.8685948428908578\n",
            "FPR@95%TPR 0.2152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прикольный метод, реально намного лучше. И по реализации простенький"
      ],
      "metadata": {
        "id": "Dxmq1j2We7xE"
      }
    }
  ]
}